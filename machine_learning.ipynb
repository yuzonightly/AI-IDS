{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine_learning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOMzw/1B9Sr2YiPlkKVKSuP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuzonightly/AI-IDS/blob/main/machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXjaM1atSadE"
      },
      "source": [
        "# Artificial Inteligence\n",
        "\n",
        "Tools:\n",
        "\n",
        "- Google Colab.\n",
        "\n",
        "Sources:\n",
        "\n",
        "- Linear Algebra.\n",
        "  - https://cs229.stanford.edu/summer2020/cs229-linalg.pdf\n",
        "  - Range $\\mathcal{R}$: https://en.wikipedia.org/wiki/Row_and_column_spaces\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PTWk4VawwhK"
      },
      "source": [
        "## Linear Algebra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlZ16nDWn53c"
      },
      "source": [
        "### Symmetric Matrices\n",
        "\n",
        "A matrix $A \\in \\mathbb{R}^{n \\times n}$ is ***symmetric*** if $A = A^{T}$. $A$ is ***anti-symmetric*** if $A = -A^{T}$. For any matrix $A \\in \\mathbb{R}^{n \\times n}$, $A + A^{T}$ is ***symmetric*** and $A - A^{T}$ is ***anti-symmetric***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUu6UpyFLood"
      },
      "source": [
        "### The Trace\n",
        "\n",
        "Sum of the diagonal elements in the matrix:\n",
        "\n",
        "$$\n",
        "trA = \\sum^{n}_{i=1}A_{ii}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owKC7P4WMMIV"
      },
      "source": [
        "### Norms\n",
        "\n",
        "The ***norm*** of a vector $||x||$ is a measure of the \"length\" of the vector. $\\ell_{2}$ norm:\n",
        "\n",
        "$$\n",
        "||x||_{2} = \\sqrt{\\sum^{n}_{i=1}x^{2}_ {i}}\n",
        "$$\n",
        "\n",
        "$\\ell$ norm:\n",
        "\n",
        "$$\n",
        "||x||_{1} = \\sum^{n}_{i=1}|x_{i}|\n",
        "$$\n",
        "\n",
        "$\\ell_{\\infty}$ norm:\n",
        "\n",
        "$$\n",
        "||x||_{\\infty} = max_{i}|x_{i}|\n",
        "$$\n",
        "\n",
        "$\\ell_{p}$ norms are parameterized by $p \\geq 1$ and defined as:\n",
        "\n",
        "$$||x||_{p} = \\left( \\sum^{n}_{i=1}|x_{i}|^{p} \\right)^{1/p}$$\n",
        "\n",
        "Norms for matrices:\n",
        "\n",
        "$$\n",
        "||A||_{F} = \\sqrt{tr(A^{T}A)}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFcNm5GNy3Wm"
      },
      "source": [
        "### Linear Independence and Rank\n",
        "\n",
        "A set of vectors $\\{x_{1}, x_{2}, x_{3}, ... x_{n}\\} \\subset \\mathbb{R}^{m}$ is ***(linearly) independent*** if no vector can be represented as a linear combination of the remaining vectors.\n",
        "\n",
        "If one vector in the set can be represented as a linear combination of the remaining vectors, then they are said to be ***(linearly) dependent***:\n",
        "\n",
        "$$\n",
        "x_{n} = \\sum_{i=1}^{n-1}α_{i}x_{i},\n",
        "$$\n",
        "\n",
        "where $α_{i} \\in \\mathbb{R}$. This means that vectors $x_{1},...,x_{n}$ are linearly dependent.\n",
        "\n",
        "The ***column rank*** of a matrix $A \\in \\mathbb{R}^{m \\times n}$ is the size of the largest subset of columns of $A$ that forms a ***linearly independent*** set. The ***row rank*** is the largest number of rows of $A$ that forms a ***linearly independent*** set.\n",
        "\n",
        "We simply say rank of $A$, denoted as $rank(A)$. We do that because, for any matrix $A$, the ***column rank*** of $A$ and the ***row rank*** of $A$ are equal. For the same matrix $A$, if $rank(A) = min(m,n)$, then $A$ is said to be full rank."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMptdr34nULV"
      },
      "source": [
        "### The Inverse of a Square Matrix\n",
        "\n",
        "The ***inverse*** of $A \\in \\mathbb{R}^{n \\times n}$ is denoted $A^{-1}$:\n",
        "\n",
        "$$\n",
        "A^{-1}A = I = AA^{-1}\n",
        "$$\n",
        "\n",
        "If the inverse of $A$ exists, then we call $A$ ***invertible*** or ***non-singular***, ***non-invertible*** or ***singular*** otherwise.\n",
        "\n",
        "Consider the equation $Ax = b$, where $a \\in \\mathbb{R}^{n \\times n}$, and $x,b \\in \\mathbb{R}^{n}$. If $A$ is invertible, then $x = A^{-1}b$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGqnIfeScpfh"
      },
      "source": [
        "### Orthogonal Matrices\n",
        "\n",
        "Two vectors $x, y \\in \\mathbb{R}^{n}$ are orthogonal if $x^{T}y = 0$. A vector $x$ is normalized if $||x||_{2} = 1$. A matrix $U \\in \\mathbb{R}$ is orthogonal if all its columns are ***ortogonal*** to each other and are ***normalized*** (the columns are ***orthonormal***).\n",
        "\n",
        "$$\n",
        "U^{T}U = I = UU^{T}\n",
        "$$\n",
        "\n",
        "The inverse of an orthogonal matrix is its transpose. If $m \\ne n$, then $U^{T}U = I$, but $I \\ne UU^{T}$. Also:\n",
        "\n",
        "$$\n",
        "||Ux||_{2} = ||x||_{2},\n",
        "$$\n",
        "\n",
        "where $x \\in \\mathbb{R}$ and $U \\in \\mathbb{R}^{n \\times n}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rsEPEhEovJJ"
      },
      "source": [
        "### Range and Nullspace of a Matrix\n",
        "\n",
        "The ***span*** of a set of vectors $\\{x_{1},...,x_{n}\\}$  is the set of all vectors that can be expressed as a ***linear combination*** of $\\{x_{1},...,x_{n}\\}$:\n",
        "\n",
        "$$\n",
        "span(\\{x_{1},...,x_{n}\\}) = \\left\\{ v : v = \\sum^{n}_{i=1}α_{i}x_{i}, α_{i} \\in \\mathbb{R} \\right\\}.\n",
        "$$\n",
        "\n",
        "If $\\{x_{1},...,x_{n}\\}$ is a set of $n$ ***linearly independent*** vectors, where $x_{i} \\in \\mathbb{R}$, then $span(\\{x_{1},...,x_{n}\\}) = \\mathbb{R}^{n}$. Which means that any vector in $\\mathbb{R}^{n}$ can be expressed as a linear combination of $x_{1}$ through $x_{n}$.\n",
        "\n",
        "The ***projection*** of a vector $y \\in \\mathbb{R}^{m}$ onto the span of $\\{x_{1},...,x_{n}\\}$ if the vector $v \\in span(\\{x_{1},...,x_{n}\\})$, such that $v$ is as close as possible to $y$:\n",
        "\n",
        "$\n",
        "Proj(y; \\{x_{1},...,x_{n}\\}) = argmin_{v \\in span(\\{x_{1},...,x_{n}\\})}||y - v||_{2}.\n",
        "$$\n",
        "\n",
        "The ***range***, or columnspace, of a matrix $A \\in \\mathbb{R}^{m \\times n}$, denoted $\\mathcal{R}(A)$, is the span of the columns of $A$:\n",
        "\n",
        "$$\n",
        "\\mathcal{R}(A) = \\{v \\in \\mathbb{R}^{m} : v = Ax,x \\in \\mathbb{R}^{n}\\}.\n",
        "$$\n",
        "\n",
        "The ***projection*** of a vector $y \\in \\mathbb{R}^{m}$ onto the ***range*** of $a$:\n",
        "\n",
        "$$\n",
        "Proj(y;A) = argmin_{v \\in \\mathcal{R}(A)}||v-y||_{2} = A(A^{T}A)^{-1}A^{T}y.\n",
        "$$\n",
        "\n",
        "If the matrix $A$ has only one column, $a \\in \\mathbb{R}^{m}$ (special case for a projection of a vector onto a line):\n",
        "\n",
        "$$\n",
        "Proj(y;a) = \\frac{aa^{T}}{a^{T}a}y.\n",
        "$$\n",
        "\n",
        "The ***nullspace*** of $A \\in \\mathbb{R}^{m \\times n}$ ($\\mathcal{N}(A)$) is the set of all vectors that equals $0$ when multiplied by $A$:\n",
        "\n",
        "$$\n",
        "\\mathcal{N}(A) = \\{x \\in \\mathbb{R}^{n} : Ax = 0\\}.\n",
        "$$\n",
        "\n",
        "$\\mathcal{R}(A^{T})$ and $\\mathcal{N}(A)$ are ***orthogonal complements***. They are **disjoint subsets** that together span the entire space of $\\mathbb{R}^{n}$, denoted $\\mathcal{R}(A^{T}) = \\mathcal{N}(A)^{\\bot}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I91WbVNLmFL0"
      },
      "source": [
        "### The Determinant\n",
        "\n",
        "$A \\in \\mathbb{R}^{n}$:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "- & a_{1}^{T} & -\\\\\n",
        "- & a_{2}^{T} & -\\\\\n",
        "- & \\vdots & -\\\\\n",
        "- & a_{n}^{T} & -\\\\\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Consider $S \\subset \\mathbb{R}^{n}$ as a set of all possible linear combinations of the row vectors $a_{1}, a_{2}, a_{3},...,a_{n} \\in \\mathbb{R}^{n}$"
      ]
    }
  ]
}