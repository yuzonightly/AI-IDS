{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine_learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMXLWDTc4klvwMm7w8zksJR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuzonightly/AI-IDS/blob/main/machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXjaM1atSadE"
      },
      "source": [
        "# Artificial Inteligence\n",
        "\n",
        "Tools:\n",
        "\n",
        "- Google Colab.\n",
        "\n",
        "Sources:\n",
        "\n",
        "- Linear Algebra.\n",
        "  - https://cs229.stanford.edu/summer2020/cs229-linalg.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PTWk4VawwhK"
      },
      "source": [
        "## Linear Algebra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlZ16nDWn53c"
      },
      "source": [
        "### Symmetric Matrices\n",
        "\n",
        "A matrix $A \\in \\mathbb{R}^{n \\times n}$ is ***symmetric*** if $A = A^{T}$. $A$ is ***anti-symmetric*** if $A = -A^{T}$. For any matrix $A \\in \\mathbb{R}^{n \\times n}$, $A + A^{T}$ is ***symmetric*** and $A - A^{T}$ is ***anti-symmetric***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUu6UpyFLood"
      },
      "source": [
        "### The Trace\n",
        "\n",
        "Sum of the diagonal elements in the matrix:\n",
        "\n",
        "$$trA = \\sum^{n}_{i=1}A_{ii}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owKC7P4WMMIV"
      },
      "source": [
        "### Norms\n",
        "\n",
        "The ***norm*** of a vector $||x||$ is a measure of the \"length\" of the vector. $\\ell_{2}$ norm:\n",
        "\n",
        "$$||x||_{2} = \\sqrt{\\sum^{n}_{i=1}x^{2}_ {i}}$$\n",
        "\n",
        "$\\ell$ norm:\n",
        "\n",
        "$$||x||_{1} = \\sum^{n}_{i=1}|x_{i}|$$\n",
        "\n",
        "$\\ell_{\\infty}$ norm:\n",
        "\n",
        "$$||x||_{\\infty} = max_{i}|x_{i}|$$\n",
        "\n",
        "$\\ell_{p}$ norms are parameterized by $p \\geq 1$ and defined as:\n",
        "\n",
        "$$||x||_{p} = \\left( \\sum^{n}_{i=1}|x_{i}|^{p} \\right)^{1/p}$$\n",
        "\n",
        "Norms for matrices:\n",
        "\n",
        "$$||A||_{F} = \\sqrt{tr(A^{T}A)}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFcNm5GNy3Wm"
      },
      "source": [
        "### Linear Independence and Rank\n",
        "\n",
        "A set of vectors $\\{x_{1}, x_{2}, x_{3}, ... x_{n}\\} \\subset \\mathbb{R}^{m}$ is ***(linearly) independent*** if no vector can be represented as a linear combination of the remaining vectors.\n",
        "\n",
        "If one vector in the set can be represented as a linear combination of the remaining vectors, then they are said to be ***(linearly) dependent***:\n",
        "\n",
        "$$x_{n} = \\sum_{i=1}^{n-1}α_{i}x_{i},$$\n",
        "\n",
        "where $α_{i} \\in \\mathbb{R}$. This means that vectors $x_{1},...,x_{n}$ are linearly dependent.\n",
        "\n",
        "The ***column rank*** of a matrix $A \\in \\mathbb{R}^{m \\times n}$ is the size of the largest subset of columns of $A$ that forms a ***linearly independent*** set. The ***row rank*** is the largest number of rows of $A$ that forms a ***linearly independent*** set.\n",
        "\n",
        "We simply say rank of $A$, denoted as $rank(A)$. We do that because, for any matrix $A$, the ***column rank*** of $A$ and the ***row rank*** of $A$ are equal. For the same matrix $A$, if $rank(A) = min(m,n)$, then $A$ is said to be full rank."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMptdr34nULV"
      },
      "source": [
        "### The Inverse of a Square Matrix\n",
        "\n",
        "The ***inverse*** of $A \\in \\mathbb{R}^{n \\times n}$ is denoted $A^{-1}$:\n",
        "\n",
        "$$A^{-1}A = I = AA^{-1}$$\n",
        "\n",
        "If the inverse of $A$ exists, then we call $A$ ***invertible*** or ***non-singular***, ***non-invertible*** or ***singular*** otherwise.\n",
        "\n",
        "Consider the equation $Ax = b$, where $a \\in \\mathbb{R}^{n \\times n}$, and $x,b \\in \\mathbb{R}^{n}$. If $A$ is invertible, then $x = A^{-1}b$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGqnIfeScpfh"
      },
      "source": [
        "### Orthogonal Matrices\n",
        "\n",
        "Two vectors $x, y \\in \\mathbb{R}^{n}$ are orthogonal if $x^{T}y = 0$. A vector $x$ is normalized if $||x||_{2} = 1$. A matrix $U \\in \\mathbb{R}$ is orthogonal if all its columns are ***ortogonal*** to each other and are ***normalized*** (the columns are ***orthonormal***).\n",
        "\n",
        "$$U^{T}U = I = UU^{T}$$\n",
        "\n",
        "The inverse of an orthogonal matrix is its transpose. If $m \\ne n$, then $U^{T}U = I$, but $I \\ne UU^{T}$. Also:\n",
        "\n",
        "$$||Ux||_{2} = ||x||_{2},$$\n",
        "\n",
        "where $x \\in \\mathbb{R}$ and $U \\in \\mathbb{R}^{n \\times n}$."
      ]
    }
  ]
}